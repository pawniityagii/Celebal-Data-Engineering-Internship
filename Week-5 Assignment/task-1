import pandas as pd
import sqlalchemy
import pyarrow.parquet as pq
import pyarrow as pa
from fastavro import writer, parse_schema

# Database connection
engine = sqlalchemy.create_engine('mysql://user:password@host/dbname')
query = "SELECT * FROM your_table"
df = pd.read_sql(query, engine)

# Save as CSV
df.to_csv('data.csv', index=False)

# Save as Parquet
table = pa.Table.from_pandas(df)
pq.write_table(table, 'data.parquet')

# Save as Avro
schema = {
    "type": "record",
    "name": "Example",
    "fields": [{"name": col, "type": "string"} for col in df.columns]
}
records = df.to_dict(orient="records")
with open('data.avro', 'wb') as out_file:
    writer(out_file, schema, records)
